{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projeto: Quais fatores mais influenciam no desempenho de um aluno no ENEM e como podemos ajudá-lo a melhorar sua performance?**\n",
    "\n",
    "**Integrantes:** Hellen Cristine Silva Rosa (RA00319076), João Victor Porto (RA00311353), Laura Gabriel Murayama (RA00319321), Maria Eduarda Bonel Iribarnegaray (RA00318891), Vinícius Ferreira de Mendonça (RA00319760), Vitória de Fátima Teixeira (RA00320578)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importando bibliotecas e definindo funções importantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 3\n",
    "\n",
    "# loading environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# importing sklearn accelerator\n",
    "from sklearnex import patch_sklearn, unpatch_sklearn\n",
    "\n",
    "# importing libraries\n",
    "import os\n",
    "import re\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import skops.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# importing sklearn functions\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, accuracy_score, f1_score, precision_recall_fscore_support, ConfusionMatrixDisplay\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# establishing connection with DB\n",
    "class db_connection():\n",
    "    '''\n",
    "    Instantiates a connection with the database.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        self.DB_URI = os.environ.get('DB_URI')\n",
    "         \n",
    "    def __enter__(self):\n",
    "        self.connection = psycopg2.connect(self.DB_URI)\n",
    "        return self.connection\n",
    "    \n",
    "    def __exit__(self, *args):\n",
    "        self.connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with db_connection() as conn, conn.cursor() as cursor:\n",
    "    query = '''\n",
    "    SELECT *\n",
    "    FROM projeto_enem.aggregated_data\n",
    "    ORDER BY \"NU_INSCRICAO\" ASC;\n",
    "    '''\n",
    "    \n",
    "    cursor.execute(query)\n",
    "    aggregated_data = cursor.fetchall()\n",
    "    aggregated_columns = tuple(desc[0] for desc in cursor.description)\n",
    "\n",
    "\n",
    "aggregated_df = pd.DataFrame(aggregated_data, columns=aggregated_columns)\n",
    "aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggregated_df = pd.read_csv('../aggregated_df.csv')\n",
    "aggregated_df = aggregated_df.replace(np.nan, None)\n",
    "aggregated_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **REQ#01: Utilizar um ou mais datasets para o treinamento dos classificadores**\n",
    "\n",
    "Utilizaremos os microdados do ENEM 2022, [disponibilizados pelo INEP](https://www.gov.br/inep/pt-br/acesso-a-informacao/dados-abertos/microdados/enem)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **REQ#02: Análise Exploratória**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verificando nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_aggregated_df = aggregated_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_aggregated_df = updated_aggregated_df.dropna(\n",
    "    subset=['NU_INSCRICAO', 'PARTICIPANTE_TP_FAIXA_ETARIA', 'PARTICIPANTE_TP_SEXO', 'PARTICIPANTE_TP_COR_RACA', 'PARTICIPANTE_TP_ST_CONCLUSAO', 'PARTICIPANTE_TP_ANO_CONCLUIU', 'PARTICIPANTE_TP_ESCOLA', 'PARTICIPANTE_IN_TREINEIRO', 'PARTICIPANTE_SG_UF_ESC', 'PARTICIPANTE_TP_PRESENCA_CN', 'PARTICIPANTE_TP_PRESENCA_CH', 'PARTICIPANTE_TP_PRESENCA_LC', 'PARTICIPANTE_TP_PRESENCA_MT', 'NOTAS_NU_NOTA_CN', 'NOTAS_NU_NOTA_CH', 'NOTAS_NU_NOTA_LC', 'NOTAS_NU_NOTA_MT', 'NOTAS_NU_NOTA_REDACAO', 'PARTICIPANTE_TP_STATUS_REDACAO', 'NOTAS_NU_NOTA_COMP1', 'NOTAS_NU_NOTA_COMP2', 'NOTAS_NU_NOTA_COMP3', 'NOTAS_NU_NOTA_COMP4', 'NOTAS_NU_NOTA_COMP5', 'PARTICIPANTE_TP_LINGUA', 'PARTICIPANTE_Q005', 'PARTICIPANTE_Q006', 'HABESTUDO_Q001', 'HABESTUDO_Q002', 'HABESTUDO_Q003', 'HABESTUDO_Q004', 'HABESTUDO_Q005', 'HABESTUDO_Q006', 'HABESTUDO_Q007', 'HABESTUDO_Q008', 'HABESTUDO_Q009', 'HABESTUDO_Q010', 'HABESTUDO_Q011', 'HABESTUDO_Q012', 'HABESTUDO_Q013', 'HABESTUDO_Q014', 'HABESTUDO_Q015', 'HABESTUDO_Q016', 'HABESTUDO_Q017', 'HABESTUDO_Q018', 'HABESTUDO_Q019', 'HABESTUDO_Q020', 'HABESTUDO_Q021', 'HABESTUDO_Q022', 'HABESTUDO_Q023', 'HABESTUDO_Q024', 'HABESTUDO_Q025A', 'HABESTUDO_Q025B', 'HABESTUDO_Q025C', 'HABESTUDO_Q025D', 'HABESTUDO_Q025E', 'HABESTUDO_Q025F', 'HABESTUDO_Q026A', 'HABESTUDO_Q026B', 'HABESTUDO_Q026C', 'HABESTUDO_Q026D', 'HABESTUDO_Q026E', 'HABESTUDO_Q026F', 'HABESTUDO_Q026G', 'HABESTUDO_Q026H', 'HABESTUDO_Q027', 'HABESTUDO_Q028A', 'HABESTUDO_Q028B', 'HABESTUDO_Q028C', 'HABESTUDO_Q028D', 'HABESTUDO_Q028E', 'HABESTUDO_Q028F', 'HABESTUDO_Q028G', 'HABESTUDO_Q028H', 'HABESTUDO_Q028I', 'HABESTUDO_Q028J', 'HABESTUDO_Q028K', 'HABESTUDO_Q028L', 'HABESTUDO_Q028M', 'HABESTUDO_Q028N', 'HABESTUDO_Q028O', 'HABESTUDO_Q028P', 'HABESTUDO_Q028Q', 'HABESTUDO_Q028R', 'HABESTUDO_Q029', 'HABESTUDO_Q030A', 'HABESTUDO_Q030B', 'HABESTUDO_Q030C', 'HABESTUDO_Q030D', 'HABESTUDO_Q030E', 'HABESTUDO_Q030F', 'HABESTUDO_Q030G', 'HABESTUDO_Q031', 'HABESTUDO_Q032A', 'HABESTUDO_Q032B', 'HABESTUDO_Q032C', 'HABESTUDO_Q032D', 'HABESTUDO_Q032E', 'HABESTUDO_Q032F', 'HABESTUDO_Q032G', 'HABESTUDO_Q033A', 'HABESTUDO_Q033B', 'HABESTUDO_Q033C', 'HABESTUDO_Q033D', 'HABESTUDO_Q033E', 'HABESTUDO_Q033F', 'HABESTUDO_Q033G', 'HABESTUDO_Q033H', 'HABESTUDO_Q033I', 'HABESTUDO_Q033J', 'HABESTUDO_Q034']\n",
    ").reset_index(drop=True)\n",
    "\n",
    "updated_aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_aggregated_df_isna = updated_aggregated_df.isna().sum()\n",
    "updated_aggregated_df_isna[updated_aggregated_df_isna != 0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando novas variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regiao_uf(vetor_uf: pd.Series) -> pd.Series:\n",
    "    '''\n",
    "    Informa a região correspondente ao estado a partir de sua sigla.\n",
    "\n",
    "    :params:\n",
    "    - vetor_uf: UF do candidato (MICRODADOS_SG_UF_ESC).\n",
    "\n",
    "    Returns a Series.\n",
    "    '''\n",
    "\n",
    "    regioes_list = []\n",
    "\n",
    "    for uf in vetor_uf:\n",
    "        regiao_uf_dict = {\n",
    "            'AM': 'Norte',\n",
    "            'RR': 'Norte',\n",
    "            'AP': 'Norte',\n",
    "            'PA': 'Norte',\n",
    "            'TO': 'Norte',\n",
    "            'RO': 'Norte',\n",
    "            'AC': 'Norte',\n",
    "            'MA': 'Nordeste',\n",
    "            'PI': 'Nordeste',\n",
    "            'CE': 'Nordeste',\n",
    "            'RN': 'Nordeste',\n",
    "            'PE': 'Nordeste',\n",
    "            'PB': 'Nordeste',\n",
    "            'SE': 'Nordeste',\n",
    "            'AL': 'Nordeste',\n",
    "            'BA': 'Nordeste',\n",
    "            'MT': 'Centro-Oeste',\n",
    "            'MS': 'Centro-Oeste',\n",
    "            'GO': 'Centro-Oeste',\n",
    "            'DF': 'Centro-Oeste',\n",
    "            'SP': 'Sudeste',\n",
    "            'RJ': 'Sudeste',\n",
    "            'ES': 'Sudeste',\n",
    "            'MG': 'Sudeste',\n",
    "            'PR': 'Sul',\n",
    "            'RS': 'Sul',\n",
    "            'SC': 'Sul',\n",
    "        }\n",
    "\n",
    "        regiao = regiao_uf_dict[uf]\n",
    "        regioes_list.append(regiao)\n",
    "\n",
    "    return pd.Series(regioes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nota_conceito(vetor_nota_media: pd.Series, porcentagem_quartis: float) -> pd.Series:\n",
    "    '''\n",
    "    Converte as notas médias dos participantes em conceitos a partir da divisão dessas notas em quartis.\n",
    "\n",
    "    :params:\n",
    "    - vetor_nota_media: nota média do candidato (MICRODADOS_NU_NOTA_MEDIA).\n",
    "    - porcentagem_quartis: tamanho de cada um dos quartis a ser didivido.\n",
    "\n",
    "    Returns a Series.\n",
    "    '''\n",
    "\n",
    "    quantile_percentages = tuple(map(lambda x: round(x, 2), np.arange(0.0, (1.0 + porcentagem_quartis), porcentagem_quartis)))\n",
    "\n",
    "    quantiles = tuple(map(lambda x: round(vetor_nota_media.quantile(x), 2), quantile_percentages))\n",
    "\n",
    "    if quantiles[0] > vetor_nota_media.min():\n",
    "        quantiles[0] = vetor_nota_media.min()\n",
    "    if quantiles[-1] < vetor_nota_media.max():\n",
    "        quantiles[-1] = vetor_nota_media.max()\n",
    "\n",
    "    quantiles_intervals = tuple(zip(quantiles, quantiles[1:]))\n",
    "\n",
    "\n",
    "    conceito_list = []\n",
    "\n",
    "    for nota_media in vetor_nota_media:\n",
    "        for interval_index, interval in enumerate(quantiles_intervals):\n",
    "            if (interval[0] <= nota_media) and (nota_media <= interval[1]):\n",
    "                conceito = interval_index\n",
    "                conceito_list.append(conceito)\n",
    "                break\n",
    "\n",
    "\n",
    "    return pd.Series(conceito_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_acertos(area_prova: str, vetor_respostas: pd.Series, vetor_gabaritos: pd.Series, vetor_linguas: pd.Series | None = None) -> pd.Series:\n",
    "    '''\n",
    "    Conta os acertos de determinada prova.\n",
    "\n",
    "    :params:\n",
    "    - area_prova: a qual área corresponde a prova.\n",
    "    - vetor_respostas: vetor de respostas do candidato.\n",
    "    - vetor_gabaritos: vetor de gabaritos dada a prova do candidato.\n",
    "    - vetor_linguas: caso 'area_prova' seja 'LC', a lingua deve ser indicada, sendo 0 para 'inglês' e 1 para 'espanhol'.\n",
    "\n",
    "    Returns a Series.\n",
    "    '''\n",
    "\n",
    "    if (area_prova == 'LC') and (isinstance(vetor_linguas, type(None))):\n",
    "        raise ValueError('vetor_linguas must be defined for a \\'LC\\' area_prova.')\n",
    "\n",
    "\n",
    "    def update_gabarito_with_language(lingua: int, gabarito: str):\n",
    "        if not isinstance(lingua, int):\n",
    "            raise ValueError('\\'lingua\\' is not defined')\n",
    "        elif lingua == 0:\n",
    "            updated_gabarito = gabarito[:5] + gabarito[10:]\n",
    "        elif lingua == 1:\n",
    "            updated_gabarito = gabarito[5:]\n",
    "        return updated_gabarito\n",
    "    \n",
    "\n",
    "    def check_answers_on_gabarito(acertos_list: list, respostas: str, gabarito: str, lingua: int | None = None):\n",
    "        if not isinstance(respostas, str):\n",
    "            acertos_list.append(None)\n",
    "        else:\n",
    "            if area_prova == 'LC':\n",
    "                gabarito = update_gabarito_with_language(lingua, gabarito)\n",
    "\n",
    "            acertos = 0\n",
    "            for r, g in zip(respostas, gabarito):\n",
    "                if r == g:\n",
    "                    acertos += 1\n",
    "            acertos_list.append(acertos)\n",
    "    \n",
    "    \n",
    "    acertos_list = []\n",
    "    if area_prova == 'LC':\n",
    "        for respostas, gabarito, lingua in zip(vetor_respostas, vetor_gabaritos, vetor_linguas):\n",
    "            check_answers_on_gabarito(acertos_list, respostas, gabarito, lingua)\n",
    "    else:\n",
    "        for respostas, gabarito in zip(vetor_respostas, vetor_gabaritos):\n",
    "            check_answers_on_gabarito(acertos_list, respostas, gabarito)\n",
    "    \n",
    "\n",
    "    return pd.Series(acertos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mediana_renda_per_capita(vetor_renda_total: pd.Series, vetor_tamanho_grupo_familiar: pd.Series) -> pd.Series:\n",
    "    '''\n",
    "    Calcula a renda per capita do grupo familiar.\n",
    "\n",
    "    :params:\n",
    "    - vetor_renda_total: item de resposta da renda total (MICRODADOS_Q006).\n",
    "    - vetor_tamanho_grupo_familiar: item de resposta do tamanho do grupo_familiar (MICRODADOS_Q005).\n",
    "\n",
    "    Returns a Series.\n",
    "    '''\n",
    "\n",
    "    renda_per_capita_list = []\n",
    "\n",
    "    for renda, tamanho_grupo_familiar in zip(vetor_renda_total, vetor_tamanho_grupo_familiar):\n",
    "        renda_correspondence_dict = {\n",
    "            'A': (0.00, 0.00),\n",
    "            'B': (0.00, 1212.00),\n",
    "            'C': (1212.01, 1818.00),\n",
    "            'D': (1818.01, 2424.00),\n",
    "            'E': (2424.01, 3030.00),\n",
    "            'F': (3030.01, 3636.00),\n",
    "            'G': (3636.01, 4848.00),\n",
    "            'H': (4848.01, 6060.00),\n",
    "            'I': (6060.01, 7272.00),\n",
    "            'J': (7272.01, 8484.00),\n",
    "            'K': (8484.01, 9696.00),\n",
    "            'L': (9696.01, 10908.00),\n",
    "            'M': (10908.01, 12120.00),\n",
    "            'N': (12120.01, 14544.00),\n",
    "            'O': (14544.01, 18180.00),\n",
    "            'P': (18180.01, 24240.00),\n",
    "            'Q': (24240.01, float('inf')),\n",
    "        }\n",
    "        intervalo_renda = renda_correspondence_dict[renda]\n",
    "\n",
    "        if intervalo_renda:\n",
    "            intervalo_renda_per_capita = tuple([amount/tamanho_grupo_familiar for amount in intervalo_renda])\n",
    "            mediana_renda_per_capita = np.median(intervalo_renda_per_capita)\n",
    "            mediana_renda_per_capita = round(mediana_renda_per_capita, 2)\n",
    "            renda_per_capita_list.append(mediana_renda_per_capita)\n",
    "        else:\n",
    "            renda_per_capita_list.append(None)\n",
    "\n",
    "    return pd.Series(renda_per_capita_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'NU_INSCRICAO', 'PARTICIPANTE_TP_FAIXA_ETARIA', 'PARTICIPANTE_TP_SEXO', 'PARTICIPANTE_TP_COR_RACA', 'PARTICIPANTE_TP_ST_CONCLUSAO', 'PARTICIPANTE_TP_ANO_CONCLUIU', 'PARTICIPANTE_TP_ESCOLA', 'PARTICIPANTE_IN_TREINEIRO', 'PARTICIPANTE_SG_UF_ESC', 'PARTICIPANTE_TP_PRESENCA_CN', 'PARTICIPANTE_TP_PRESENCA_CH', 'PARTICIPANTE_TP_PRESENCA_LC', 'PARTICIPANTE_TP_PRESENCA_MT', 'NOTAS_NU_NOTA_CN', 'NOTAS_NU_NOTA_CH', 'NOTAS_NU_NOTA_LC', 'NOTAS_NU_NOTA_MT', 'NOTAS_NU_NOTA_REDACAO', 'PARTICIPANTE_TP_STATUS_REDACAO', 'NOTAS_NU_NOTA_COMP1', 'NOTAS_NU_NOTA_COMP2', 'NOTAS_NU_NOTA_COMP3', 'NOTAS_NU_NOTA_COMP4', 'NOTAS_NU_NOTA_COMP5', 'PARTICIPANTE_TP_LINGUA', 'PARTICIPANTE_Q005', 'PARTICIPANTE_Q006', 'HABESTUDO_Q001', 'HABESTUDO_Q002', 'HABESTUDO_Q003', 'HABESTUDO_Q004', 'HABESTUDO_Q005', 'HABESTUDO_Q006', 'HABESTUDO_Q007', 'HABESTUDO_Q008', 'HABESTUDO_Q009', 'HABESTUDO_Q010', 'HABESTUDO_Q011', 'HABESTUDO_Q012', 'HABESTUDO_Q013', 'HABESTUDO_Q014', 'HABESTUDO_Q015', 'HABESTUDO_Q016', 'HABESTUDO_Q017', 'HABESTUDO_Q018', 'HABESTUDO_Q019', 'HABESTUDO_Q020', 'HABESTUDO_Q021', 'HABESTUDO_Q022', 'HABESTUDO_Q023', 'HABESTUDO_Q024', 'HABESTUDO_Q025A', 'HABESTUDO_Q025B', 'HABESTUDO_Q025C', 'HABESTUDO_Q025D', 'HABESTUDO_Q025E', 'HABESTUDO_Q025F', 'HABESTUDO_Q026A', 'HABESTUDO_Q026B', 'HABESTUDO_Q026C', 'HABESTUDO_Q026D', 'HABESTUDO_Q026E', 'HABESTUDO_Q026F', 'HABESTUDO_Q026G', 'HABESTUDO_Q026H', 'HABESTUDO_Q027', 'HABESTUDO_Q028A', 'HABESTUDO_Q028B', 'HABESTUDO_Q028C', 'HABESTUDO_Q028D', 'HABESTUDO_Q028E', 'HABESTUDO_Q028F', 'HABESTUDO_Q028G', 'HABESTUDO_Q028H', 'HABESTUDO_Q028I', 'HABESTUDO_Q028J', 'HABESTUDO_Q028K', 'HABESTUDO_Q028L', 'HABESTUDO_Q028M', 'HABESTUDO_Q028N', 'HABESTUDO_Q028O', 'HABESTUDO_Q028P', 'HABESTUDO_Q028Q', 'HABESTUDO_Q028R', 'HABESTUDO_Q029', 'HABESTUDO_Q030A', 'HABESTUDO_Q030B', 'HABESTUDO_Q030C', 'HABESTUDO_Q030D', 'HABESTUDO_Q030E', 'HABESTUDO_Q030F', 'HABESTUDO_Q030G', 'HABESTUDO_Q031', 'HABESTUDO_Q032A', 'HABESTUDO_Q032B', 'HABESTUDO_Q032C', 'HABESTUDO_Q032D', 'HABESTUDO_Q032E', 'HABESTUDO_Q032F', 'HABESTUDO_Q032G', 'HABESTUDO_Q033A', 'HABESTUDO_Q033B', 'HABESTUDO_Q033C', 'HABESTUDO_Q033D', 'HABESTUDO_Q033E', 'HABESTUDO_Q033F', 'HABESTUDO_Q033G', 'HABESTUDO_Q033H', 'HABESTUDO_Q033I', 'HABESTUDO_Q033J', 'HABESTUDO_Q034'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_aggregated_df.loc[:, 'PARTICIPANTE_REGIAO_ESCOLA'] = get_regiao_uf(updated_aggregated_df['PARTICIPANTE_SG_UF_ESC'])\n",
    "\n",
    "updated_aggregated_df.loc[:, 'NOTAS_NU_NOTA_MEDIA'] = pd.Series(map(lambda x: round(x, 2), (updated_aggregated_df['NOTAS_NU_NOTA_CN'] + updated_aggregated_df['NOTAS_NU_NOTA_CH'] + updated_aggregated_df['NOTAS_NU_NOTA_LC'] + updated_aggregated_df['NOTAS_NU_NOTA_MT'] + updated_aggregated_df['NOTAS_NU_NOTA_REDACAO']) / 5))\n",
    "\n",
    "updated_aggregated_df.loc[:, 'NOTAS_NU_NOTA_CONCEITO'] = get_nota_conceito(updated_aggregated_df['NOTAS_NU_NOTA_MEDIA'], 0.25)\n",
    "\n",
    "updated_aggregated_df.loc[:, 'NOTAS_NU_ACERTOS_CN'] = count_acertos('CN', updated_aggregated_df['NOTAS_TX_RESPOSTAS_CN'], updated_aggregated_df['NOTAS_TX_GABARITO_CN'])\n",
    "updated_aggregated_df.loc[:, 'NOTAS_NU_ACERTOS_CH'] = count_acertos('CH', updated_aggregated_df['NOTAS_TX_RESPOSTAS_CH'], updated_aggregated_df['NOTAS_TX_GABARITO_CH'])\n",
    "updated_aggregated_df.loc[:, 'NOTAS_NU_ACERTOS_LC'] = count_acertos('LC', updated_aggregated_df['NOTAS_TX_RESPOSTAS_LC'], updated_aggregated_df['NOTAS_TX_GABARITO_LC'], updated_aggregated_df['NOTAS_TP_LINGUA'])\n",
    "updated_aggregated_df.loc[:, 'NOTAS_NU_ACERTOS_MT'] = count_acertos('MT', updated_aggregated_df['NOTAS_TX_RESPOSTAS_MT'], updated_aggregated_df['NOTAS_TX_GABARITO_MT'])\n",
    "\n",
    "updated_aggregated_df.loc[:, 'NOTAS_NU_ACERTOS_TOTAL'] = updated_aggregated_df['NOTAS_NU_ACERTOS_CN'] + updated_aggregated_df['NOTAS_NU_ACERTOS_CH'] + updated_aggregated_df['NOTAS_NU_ACERTOS_LC'] + updated_aggregated_df['NOTAS_NU_ACERTOS_MT']\n",
    "updated_aggregated_df.loc[:, 'NOTAS_NU_ACERTOS_MEDIO'] = round(updated_aggregated_df['NOTAS_NU_ACERTOS_TOTAL'] / 4, 2)\n",
    "\n",
    "updated_aggregated_df.loc[:, 'PARTICIPANTE_RENDA_PER_CAPITA'] = get_mediana_renda_per_capita(updated_aggregated_df['PARTICIPANTE_Q006'], updated_aggregated_df['PARTICIPANTE_Q005'])\n",
    "\n",
    "\n",
    "updated_aggregated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hab_estudo_category_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Une as colunas de respostas dos hábitos de estudo por categoria, normalizando as respostas.\n",
    "\n",
    "    :params:\n",
    "    - df: DataFrame com todos os dados para substituição.\n",
    "\n",
    "    Returns a DataFrame.\n",
    "    '''\n",
    "\n",
    "    # colocar variáveis em ordem crescente de dificuldade/falta de estudo (positividade)\n",
    "    # em caso de sim/não, utilizar 'sim' como maior\n",
    "    hab_estudo_correspondence_dict = {\n",
    "        'HABESTUDO_ST_MAT_PERC_APR': {\n",
    "            'HABESTUDO_Q001': ('E', 'D', 'C', 'B', 'A'),\n",
    "            'HABESTUDO_Q002': ('C', 'B', 'A'),\n",
    "            'HABESTUDO_Q003': ('E', 'D', 'C', 'B', 'A'),\n",
    "            'HABESTUDO_Q004': ('F', 'E', 'D', 'C', 'B', 'A'),\n",
    "            },\n",
    "        'HABESTUDO_GES_TEMP_PLAN_EST': {\n",
    "            'HABESTUDO_Q005': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q006': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q007': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q008': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q021': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q022': ('A', 'B', 'C', 'D'),\n",
    "            },\n",
    "        'HABESTUDO_PRAT_EST_PES': {\n",
    "            'HABESTUDO_Q009': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q010': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q011': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q012': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q013': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q014': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q015': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q016': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q017': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q018': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q019': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q020': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q023': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q024': ('A', 'B', 'C', 'D'),\n",
    "            },\n",
    "        'HABESTUDO_TECN_TP_ACES': {\n",
    "            'HABESTUDO_Q025A': ('B', 'A'),\n",
    "            'HABESTUDO_Q025B': ('B', 'A'),\n",
    "            'HABESTUDO_Q025C': ('B', 'A'),\n",
    "            'HABESTUDO_Q025D': ('B', 'A'),\n",
    "            'HABESTUDO_Q025E': ('B', 'A'),\n",
    "            'HABESTUDO_Q025F': ('B', 'A'),\n",
    "            'HABESTUDO_Q026A': ('B', 'A'),\n",
    "            'HABESTUDO_Q026B': ('B', 'A'),\n",
    "            'HABESTUDO_Q026C': ('B', 'A'),\n",
    "            'HABESTUDO_Q026D': ('B', 'A'),\n",
    "            'HABESTUDO_Q026E': ('B', 'A'),\n",
    "            'HABESTUDO_Q026F': ('B', 'A'),\n",
    "            'HABESTUDO_Q026G': ('B', 'A'),\n",
    "            'HABESTUDO_Q026H': ('B', 'A'),\n",
    "            },\n",
    "        'HABESTUDO_PROB_ROT_EST': {\n",
    "            'HABESTUDO_Q027': ('B', 'A'),\n",
    "            'HABESTUDO_Q028A': ('B', 'A'),\n",
    "            'HABESTUDO_Q028B': ('B', 'A'),\n",
    "            'HABESTUDO_Q028C': ('B', 'A'),\n",
    "            'HABESTUDO_Q028D': ('B', 'A'),\n",
    "            'HABESTUDO_Q028E': ('B', 'A'),\n",
    "            'HABESTUDO_Q028F': ('B', 'A'),\n",
    "            'HABESTUDO_Q028G': ('B', 'A'),\n",
    "            'HABESTUDO_Q028H': ('B', 'A'),\n",
    "            'HABESTUDO_Q028I': ('B', 'A'),\n",
    "            'HABESTUDO_Q028J': ('B', 'A'),\n",
    "            'HABESTUDO_Q028K': ('B', 'A'),\n",
    "            'HABESTUDO_Q028L': ('B', 'A'),\n",
    "            'HABESTUDO_Q028M': ('B', 'A'),\n",
    "            'HABESTUDO_Q028N': ('B', 'A'),\n",
    "            'HABESTUDO_Q028O': ('B', 'A'),\n",
    "            'HABESTUDO_Q028P': ('B', 'A'),\n",
    "            'HABESTUDO_Q028Q': ('B', 'A'),\n",
    "            'HABESTUDO_Q028R': ('B', 'A'),\n",
    "            },\n",
    "        'HABESTUDO_DIF_INFR': {\n",
    "            'HABESTUDO_Q029': ('B', 'A'),\n",
    "            'HABESTUDO_Q030A': ('B', 'A'),\n",
    "            'HABESTUDO_Q030B': ('B', 'A'),\n",
    "            'HABESTUDO_Q030C': ('B', 'A'),\n",
    "            'HABESTUDO_Q030D': ('B', 'A'),\n",
    "            'HABESTUDO_Q030E': ('B', 'A'),\n",
    "            'HABESTUDO_Q030F': ('B', 'A'),\n",
    "            'HABESTUDO_Q030G': ('B', 'A'),\n",
    "            },\n",
    "        'HABESTUDO_AJUD_TERC': {\n",
    "            'HABESTUDO_Q031': ('C', 'A', 'B'),\n",
    "            'HABESTUDO_Q032A': ('B', 'A'),\n",
    "            'HABESTUDO_Q032B': ('B', 'A'),\n",
    "            'HABESTUDO_Q032C': ('B', 'A'),\n",
    "            'HABESTUDO_Q032D': ('B', 'A'),\n",
    "            'HABESTUDO_Q032E': ('B', 'A'),\n",
    "            'HABESTUDO_Q032F': ('B', 'A'),\n",
    "            'HABESTUDO_Q032G': ('B', 'A'),\n",
    "            'HABESTUDO_Q033A': ('B', 'A'),\n",
    "            'HABESTUDO_Q033B': ('B', 'A'),\n",
    "            'HABESTUDO_Q033C': ('B', 'A'),\n",
    "            'HABESTUDO_Q033D': ('B', 'A'),\n",
    "            'HABESTUDO_Q033E': ('B', 'A'),\n",
    "            'HABESTUDO_Q033F': ('B', 'A'),\n",
    "            'HABESTUDO_Q033G': ('B', 'A'),\n",
    "            'HABESTUDO_Q033H': ('B', 'A'),\n",
    "            'HABESTUDO_Q033I': ('B', 'A'),\n",
    "            'HABESTUDO_Q033J': ('B', 'A'),\n",
    "            },\n",
    "        'HABESTUDO_AVAL_PROP_EXP': {\n",
    "            'HABESTUDO_Q034': ('A', 'B', 'C', 'D', 'E'),\n",
    "            },\n",
    "    }\n",
    "\n",
    "\n",
    "    for column_name, column_questions_dict in hab_estudo_correspondence_dict.items():\n",
    "        column_series_dict = {}\n",
    "\n",
    "        for question_name, question_value_list in column_questions_dict.items():\n",
    "            question_series = []\n",
    "            \n",
    "            for student_answer in df[question_name]:\n",
    "                row_value = question_value_list.index(student_answer) / (len(question_value_list) - 1)\n",
    "                row_value = round(row_value, 2)\n",
    "                question_series.append(row_value)\n",
    "            \n",
    "            column_series_dict[question_name] = question_series\n",
    "\n",
    "        column_series = pd.Series(zip(*column_series_dict.values()))\n",
    "        column_series = column_series.apply(lambda values_tuple: sum(values_tuple))\n",
    "\n",
    "        df.loc[:, column_name] = column_series\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_aggregated_df = get_hab_estudo_category_values(updated_aggregated_df)\n",
    "updated_aggregated_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtrando variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interest_variables = ['NU_INSCRICAO', 'PARTICIPANTE_TP_FAIXA_ETARIA', 'PARTICIPANTE_TP_SEXO', 'PARTICIPANTE_TP_COR_RACA', 'PARTICIPANTE_TP_ST_CONCLUSAO', 'PARTICIPANTE_TP_ANO_CONCLUIU', 'PARTICIPANTE_TP_ESCOLA', 'PARTICIPANTE_IN_TREINEIRO', 'PARTICIPANTE_REGIAO_ESCOLA', 'PARTICIPANTE_TP_PRESENCA_CN', 'PARTICIPANTE_TP_PRESENCA_CH', 'PARTICIPANTE_TP_PRESENCA_LC', 'PARTICIPANTE_TP_PRESENCA_MT', 'NOTAS_NU_NOTA_CN', 'NOTAS_NU_NOTA_CH', 'NOTAS_NU_NOTA_LC', 'NOTAS_NU_NOTA_MT', 'NOTAS_NU_NOTA_REDACAO', 'PARTICIPANTE_TP_STATUS_REDACAO', 'NOTAS_NU_NOTA_COMP1', 'NOTAS_NU_NOTA_COMP2', 'NOTAS_NU_NOTA_COMP3', 'NOTAS_NU_NOTA_COMP4', 'NOTAS_NU_NOTA_COMP5', 'NOTAS_NU_NOTA_MEDIA', 'NOTAS_NU_NOTA_CONCEITO', 'NOTAS_NU_ACERTOS_CN', 'NOTAS_NU_ACERTOS_CH', 'NOTAS_NU_ACERTOS_LC', 'NOTAS_NU_ACERTOS_MT', 'NOTAS_NU_ACERTOS_TOTAL', 'NOTAS_NU_ACERTOS_MEDIO', 'PARTICIPANTE_TP_LINGUA', 'PARTICIPANTE_RENDA_PER_CAPITA', 'HABESTUDO_ST_MAT_PERC_APR', 'HABESTUDO_GES_TEMP_PLAN_EST', 'HABESTUDO_PRAT_EST_PES', 'HABESTUDO_TECN_TP_ACES', 'HABESTUDO_PROB_ROT_EST', 'HABESTUDO_DIF_INFR', 'HABESTUDO_AJUD_TERC', 'HABESTUDO_AVAL_PROP_EXP']\n",
    "\n",
    "filtered_aggregated_df = updated_aggregated_df.loc[:, interest_variables]\n",
    "filtered_aggregated_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excluindo rendas per capita infinitas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "renda_inf_indexes = filtered_aggregated_df[filtered_aggregated_df['PARTICIPANTE_RENDA_PER_CAPITA'] == float('inf')].index\n",
    "\n",
    "filtered_aggregated_df = filtered_aggregated_df.drop(index=renda_inf_indexes).reset_index(drop=True)\n",
    "filtered_aggregated_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exportando dados localmente e para o DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_aggregated_df.to_csv('../filtered_aggregated_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_aggregated_data_creation_query = '''\n",
    "CREATE TABLE projeto_enem.filtered_aggregated_data (\n",
    "\t\"NU_INSCRICAO\" BIGINT PRIMARY KEY,\n",
    "\t\"PARTICIPANTE_TP_FAIXA_ETARIA\" INTEGER,\n",
    "\t\"PARTICIPANTE_TP_SEXO\" VARCHAR(1),\n",
    "\t\"PARTICIPANTE_TP_COR_RACA\" INTEGER,\n",
    "\t\"PARTICIPANTE_TP_ST_CONCLUSAO\" INTEGER,\n",
    "\t\"PARTICIPANTE_TP_ANO_CONCLUIU\" INTEGER,\n",
    "\t\"PARTICIPANTE_TP_ESCOLA\" INTEGER,\n",
    "\t\"PARTICIPANTE_IN_TREINEIRO\" INTEGER,\n",
    "\t\"PARTICIPANTE_REGIAO_ESCOLA\" VARCHAR(12),\n",
    "\t\"PARTICIPANTE_TP_PRESENCA_CN\" INTEGER,\n",
    "\t\"PARTICIPANTE_TP_PRESENCA_CH\" INTEGER,\n",
    "\t\"PARTICIPANTE_TP_PRESENCA_LC\" INTEGER,\n",
    "\t\"PARTICIPANTE_TP_PRESENCA_MT\" INTEGER,\n",
    "\t\"NOTAS_NU_NOTA_CN\" FLOAT,\n",
    "\t\"NOTAS_NU_NOTA_CH\" FLOAT,\n",
    "\t\"NOTAS_NU_NOTA_LC\" FLOAT,\n",
    "\t\"NOTAS_NU_NOTA_MT\" FLOAT,\n",
    "\t\"NOTAS_NU_NOTA_REDACAO\" FLOAT,\n",
    "\t\"PARTICIPANTE_TP_STATUS_REDACAO\" FLOAT,\n",
    "\t\"NOTAS_NU_NOTA_COMP1\" FLOAT,\n",
    "\t\"NOTAS_NU_NOTA_COMP2\" FLOAT,\n",
    "\t\"NOTAS_NU_NOTA_COMP3\" FLOAT,\n",
    "\t\"NOTAS_NU_NOTA_COMP4\" FLOAT,\n",
    "\t\"NOTAS_NU_NOTA_COMP5\" FLOAT,\n",
    "\t\"NOTAS_NU_NOTA_MEDIA\" FLOAT,\n",
    "    \"NOTAS_NU_NOTA_CONCEITO\" INTEGER,\n",
    "\t\"NOTAS_NU_ACERTOS_CN\" INTEGER,\n",
    "\t\"NOTAS_NU_ACERTOS_CH\" INTEGER,\n",
    "\t\"NOTAS_NU_ACERTOS_LC\" INTEGER,\n",
    "\t\"NOTAS_NU_ACERTOS_MT\" INTEGER,\n",
    "\t\"NOTAS_NU_ACERTOS_TOTAL\" INTEGER,\n",
    "\t\"NOTAS_NU_ACERTOS_MEDIO\" FLOAT,\n",
    "\t\"PARTICIPANTE_TP_LINGUA\" INTEGER,\n",
    "\t\"PARTICIPANTE_RENDA_PER_CAPITA\" FLOAT,\n",
    "\t\"HABESTUDO_ST_MAT_PERC_APR\" FLOAT,\n",
    "\t\"HABESTUDO_GES_TEMP_PLAN_EST\" FLOAT,\n",
    "\t\"HABESTUDO_PRAT_EST_PES\" FLOAT,\n",
    "\t\"HABESTUDO_TECN_TP_ACES\" FLOAT,\n",
    "\t\"HABESTUDO_PROB_ROT_EST\" FLOAT,\n",
    "\t\"HABESTUDO_DIF_INFR\" FLOAT,\n",
    "\t\"HABESTUDO_AJUD_TERC\" FLOAT,\n",
    "\t\"HABESTUDO_AVAL_PROP_EXP\" FLOAT\n",
    ");\n",
    "'''\n",
    "\n",
    "filtered_aggregated_csv_query = '''\n",
    "COPY projeto_enem.filtered_aggregated_data(\"NU_INSCRICAO\", \"PARTICIPANTE_TP_FAIXA_ETARIA\", \"PARTICIPANTE_TP_SEXO\", \"PARTICIPANTE_TP_COR_RACA\", \"PARTICIPANTE_TP_ST_CONCLUSAO\", \"PARTICIPANTE_TP_ANO_CONCLUIU\", \"PARTICIPANTE_TP_ESCOLA\", \"PARTICIPANTE_IN_TREINEIRO\", \"PARTICIPANTE_REGIAO_ESCOLA\", \"PARTICIPANTE_TP_PRESENCA_CN\", \"PARTICIPANTE_TP_PRESENCA_CH\", \"PARTICIPANTE_TP_PRESENCA_LC\", \"PARTICIPANTE_TP_PRESENCA_MT\", \"NOTAS_NU_NOTA_CN\", \"NOTAS_NU_NOTA_CH\", \"NOTAS_NU_NOTA_LC\", \"NOTAS_NU_NOTA_MT\", \"NOTAS_NU_NOTA_REDACAO\", \"PARTICIPANTE_TP_STATUS_REDACAO\", \"NOTAS_NU_NOTA_COMP1\", \"NOTAS_NU_NOTA_COMP2\", \"NOTAS_NU_NOTA_COMP3\", \"NOTAS_NU_NOTA_COMP4\", \"NOTAS_NU_NOTA_COMP5\", \"NOTAS_NU_NOTA_MEDIA\", \"NOTAS_NU_NOTA_CONCEITO\", \"NOTAS_NU_ACERTOS_CN\", \"NOTAS_NU_ACERTOS_CH\", \"NOTAS_NU_ACERTOS_LC\", \"NOTAS_NU_ACERTOS_MT\", \"NOTAS_NU_ACERTOS_TOTAL\", \"NOTAS_NU_ACERTOS_MEDIO\", \"PARTICIPANTE_TP_LINGUA\", \"PARTICIPANTE_RENDA_PER_CAPITA\", \"HABESTUDO_ST_MAT_PERC_APR\", \"HABESTUDO_GES_TEMP_PLAN_EST\", \"HABESTUDO_PRAT_EST_PES\", \"HABESTUDO_TECN_TP_ACES\", \"HABESTUDO_PROB_ROT_EST\", \"HABESTUDO_DIF_INFR\", \"HABESTUDO_AJUD_TERC\", \"HABESTUDO_AVAL_PROP_EXP\")\n",
    "FROM STDIN\n",
    "WITH (DELIMITER ',',\n",
    "ENCODING 'utf8',\n",
    "FORMAT CSV,\n",
    "HEADER);\n",
    "'''\n",
    "\n",
    "\n",
    "with db_connection() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(filtered_aggregated_data_creation_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    with open('../filtered_aggregated_df.csv', encoding='utf8') as filtered_aggregated_csv_file:\n",
    "        cursor.copy_expert(filtered_aggregated_csv_query, filtered_aggregated_csv_file)\n",
    "        conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecionando variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with db_connection() as conn, conn.cursor() as cursor:\n",
    "    query = '''\n",
    "    SELECT *\n",
    "    FROM projeto_enem.filtered_aggregated_data\n",
    "    ORDER BY \"NU_INSCRICAO\" ASC;\n",
    "    '''\n",
    "    \n",
    "    cursor.execute(query)\n",
    "    filtered_aggregated_data = cursor.fetchall()\n",
    "    filtered_aggregated_columns = tuple(desc[0] for desc in cursor.description)\n",
    "\n",
    "\n",
    "filtered_aggregated_df = pd.DataFrame(filtered_aggregated_data, columns=filtered_aggregated_columns)\n",
    "filtered_aggregated_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pré-processamento**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**nominal:** 'PARTICIPANTE_TP_SEXO', 'PARTICIPANTE_REGIAO_ESCOLA'\n",
    "\n",
    "**numerical:** 'NU_INSCRICAO', 'PARTICIPANTE_TP_FAIXA_ETARIA', 'PARTICIPANTE_TP_COR_RACA', 'PARTICIPANTE_TP_ST_CONCLUSAO', 'PARTICIPANTE_TP_ANO_CONCLUIU', 'PARTICIPANTE_TP_ESCOLA', 'PARTICIPANTE_IN_TREINEIRO', 'PARTICIPANTE_TP_PRESENCA_CN', 'PARTICIPANTE_TP_PRESENCA_CH', 'PARTICIPANTE_TP_PRESENCA_LC', 'PARTICIPANTE_TP_PRESENCA_MT', 'NOTAS_NU_NOTA_CN', 'NOTAS_NU_NOTA_CH', 'NOTAS_NU_NOTA_LC', 'NOTAS_NU_NOTA_MT', 'NOTAS_NU_NOTA_REDACAO', 'PARTICIPANTE_TP_STATUS_REDACAO', 'NOTAS_NU_NOTA_COMP1', 'NOTAS_NU_NOTA_COMP2', 'NOTAS_NU_NOTA_COMP3', 'NOTAS_NU_NOTA_COMP4', 'NOTAS_NU_NOTA_COMP5', 'NOTAS_NU_NOTA_MEDIA', 'NOTAS_NU_NOTA_CONCEITO', 'NOTAS_NU_ACERTOS_CN', 'NOTAS_NU_ACERTOS_CH', 'NOTAS_NU_ACERTOS_LC', 'NOTAS_NU_ACERTOS_MT', 'NOTAS_NU_ACERTOS_TOTAL', 'NOTAS_NU_ACERTOS_MEDIO', 'PARTICIPANTE_TP_LINGUA', 'PARTICIPANTE_RENDA_PER_CAPITA', 'HABESTUDO_ST_MAT_PERC_APR', 'HABESTUDO_GES_TEMP_PLAN_EST', 'HABESTUDO_PRAT_EST_PES', 'HABESTUDO_TECN_TP_ACES', 'HABESTUDO_PROB_ROT_EST', 'HABESTUDO_DIF_INFR', 'HABESTUDO_AJUD_TERC', 'HABESTUDO_AVAL_PROP_EXP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_features = list(set(filtered_aggregated_df.select_dtypes(include='object').columns.values))\n",
    "numerical_features = list(set(filtered_aggregated_df.select_dtypes(exclude='object').columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('nominal', nominal_transformer, nominal_features),\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = filtered_aggregated_df.drop(columns=['NU_INSCRICAO', 'NOTAS_NU_NOTA_MEDIA', 'NOTAS_NU_NOTA_CONCEITO'])\n",
    "y_numerical = filtered_aggregated_df['NOTAS_NU_NOTA_MEDIA']\n",
    "y_categorical = filtered_aggregated_df['NOTAS_NU_NOTA_CONCEITO']\n",
    "\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "y_numerical_transformed = y_numerical\n",
    "y_categorical_transformed = y_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_feature_names = preprocessor.get_feature_names_out()\n",
    "preprocessor_feature_names = [re.sub(r'.+__', '', item) for item in preprocessor_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = pd.DataFrame(X_transformed, columns=preprocessor_feature_names)\n",
    "X_transformed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avaliando correlação**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(ax, train_data, title):\n",
    "    corr = train_data.corr(method='spearman')\n",
    "    cmap = sns.diverging_palette(255, 255, sep=1, as_cmap=True)\n",
    "    mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "    graph = sns.heatmap(corr, annot=True, vmin=-1, vmax=1, fmt='.1%', cmap=cmap, mask=mask, ax=ax)\n",
    "    graph.set_title(title, pad=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(32, 16), constrained_layout=True)\n",
    "\n",
    "plot_corr(ax, X_transformed, 'Mapa de correlação entre variáveis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['PARTICIPANTE_TP_ST_CONCLUSAO', 'PARTICIPANTE_TP_ANO_CONCLUIU', 'PARTICIPANTE_IN_TREINEIRO', 'PARTICIPANTE_TP_PRESENCA_CN', 'PARTICIPANTE_TP_PRESENCA_CH', 'PARTICIPANTE_TP_PRESENCA_LC', 'PARTICIPANTE_TP_PRESENCA_MT', 'PARTICIPANTE_TP_SEXO_M', 'NOTAS_NU_ACERTOS_MEDIO', 'NOTAS_NU_ACERTOS_CN', 'NOTAS_NU_ACERTOS_CH', 'NOTAS_NU_ACERTOS_LC', 'NOTAS_NU_ACERTOS_MT', 'NOTAS_NU_NOTA_CN', 'NOTAS_NU_NOTA_CH', 'NOTAS_NU_NOTA_LC', 'NOTAS_NU_NOTA_MT', 'NOTAS_NU_NOTA_REDACAO', 'PARTICIPANTE_TP_STATUS_REDACAO', 'NOTAS_NU_NOTA_COMP1', 'NOTAS_NU_NOTA_COMP2', 'NOTAS_NU_NOTA_COMP3', 'NOTAS_NU_NOTA_COMP4', 'NOTAS_NU_NOTA_COMP5', 'NOTAS_NU_ACERTOS_TOTAL', 'PARTICIPANTE_TP_LINGUA']\n",
    "\n",
    "X_transformed_dropped = X_transformed.drop(columns=columns_to_drop)\n",
    "X_transformed_dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 10), constrained_layout=True)\n",
    "\n",
    "plot_corr(ax, X_transformed_dropped, 'Mapa de correlação entre variáveis')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conclusões:*\n",
    "- Linguagens e Humanas são as áreas que mais influenciam no número de acertos total;\n",
    "- A competência 5 é a que mais influencia na nota de Redação;\n",
    "- As categorias Gestão de Tempo e Planejamento de Estudos e Práticas de Estudo e Pesquisa são as mais relacionadas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Avaliando importância das variáveis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical_train, X_numerical_test, y_numerical_train, y_numerical_test = train_test_split(X_transformed_dropped, y_numerical_transformed, test_size=0.3, random_state=SEED)\n",
    "\n",
    "X_categorical_train, X_categorical_test, y_categorical_train, y_categorical_test = train_test_split(X_transformed_dropped, y_categorical_transformed, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accelerating sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=SEED)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_pipe.fit(X_categorical_train, y_categorical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_accuracy_scores = cross_val_score(randomforest_classifier_pipe, X_transformed_dropped, y_categorical_transformed, cv=5, scoring='balanced_accuracy')\n",
    "randomforest_classifier_accuracy_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_precision_scores = cross_val_score(randomforest_classifier_pipe, X_transformed_dropped, y_categorical_transformed, cv=5, scoring='precision_weighted')\n",
    "randomforest_classifier_precision_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_recall_scores = cross_val_score(randomforest_classifier_pipe, X_transformed_dropped, y_categorical_transformed, cv=5, scoring='recall_weighted')\n",
    "randomforest_classifier_recall_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_f1_scores = cross_val_score(randomforest_classifier_pipe, X_transformed_dropped, y_categorical_transformed, cv=5, scoring='f1_weighted')\n",
    "randomforest_classifier_f1_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(randomforest_classifier_pipe, X_transformed_dropped, y_categorical_transformed, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_feature_importances = pd.Series(randomforest_classifier_pipe['classifier'].feature_importances_, index=X_categorical_train.columns)\n",
    "randomforest_classifier_feature_importances = randomforest_classifier_feature_importances.sort_values(ascending=False)\n",
    "randomforest_classifier_feature_importances = randomforest_classifier_feature_importances.apply(lambda x: round(100*x, 2))\n",
    "randomforest_classifier_feature_importances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', RandomForestRegressor(random_state=SEED)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_pipe.fit(X_numerical_train, y_numerical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_mae_scores = -1 * cross_val_score(randomforest_regressor_pipe, X_transformed_dropped, y_numerical_transformed, cv=5, scoring='neg_mean_absolute_error')\n",
    "randomforest_regressor_mae_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_rmse_scores = -1 * cross_val_score(randomforest_regressor_pipe, X_transformed_dropped, y_numerical_transformed, cv=5, scoring='neg_root_mean_squared_error')\n",
    "randomforest_regressor_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_r2_scores = cross_val_score(randomforest_regressor_pipe, X_transformed_dropped, y_numerical_transformed, cv=5, scoring='r2')\n",
    "randomforest_regressor_r2_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_mape_scores = -1 * cross_val_score(randomforest_regressor_pipe, X_transformed_dropped, y_numerical_transformed, cv=5, scoring='neg_mean_absolute_percentage_error')\n",
    "randomforest_regressor_mape_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_feature_importances = pd.Series(randomforest_regressor_pipe['regressor'].feature_importances_, index=X_numerical_train.columns)\n",
    "randomforest_regressor_feature_importances = randomforest_regressor_feature_importances.sort_values(ascending=False)\n",
    "randomforest_regressor_feature_importances = randomforest_regressor_feature_importances.apply(lambda x: round(100*x, 2))\n",
    "randomforest_regressor_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decelerating sklearn\n",
    "unpatch_sklearn()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilizar hábitos de estudo mais significativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_interest_hab_estudo(filtered_df: pd.DataFrame, full_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    '''\n",
    "    Substitui as colunas de categoria dos hábitos de estudo mais significativas e deleta as não utilizadas.\n",
    "\n",
    "    :params:\n",
    "    - filtered_df: DataFrame previamente tratado com todos os dados para substituição.\n",
    "    - full_df: DataFrame completo para extração das colunas individuais de hábitos de estudo.\n",
    "\n",
    "    Returns a DataFrame.\n",
    "    '''\n",
    "\n",
    "    filtered_df = filtered_df.drop(columns=['HABESTUDO_ST_MAT_PERC_APR', 'HABESTUDO_TECN_TP_ACES', 'HABESTUDO_DIF_INFR', 'HABESTUDO_AJUD_TERC', 'HABESTUDO_AVAL_PROP_EXP'])\n",
    "\n",
    "\n",
    "    hab_estudo_transformation_dict = {\n",
    "        'HABESTUDO_GES_TEMP_PLAN_EST': {\n",
    "            'HABESTUDO_Q005': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q006': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q007': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q008': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q021': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q022': ('A', 'B', 'C', 'D'),\n",
    "            },\n",
    "        'HABESTUDO_PRAT_EST_PES': {\n",
    "            'HABESTUDO_Q009': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q010': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q011': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q012': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q013': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q014': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q015': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q016': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q017': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q018': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q019': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q020': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q023': ('A', 'B', 'C', 'D'),\n",
    "            'HABESTUDO_Q024': ('A', 'B', 'C', 'D'),\n",
    "            },\n",
    "        'HABESTUDO_PROB_ROT_EST': {\n",
    "            'HABESTUDO_Q027': ('B', 'A'),\n",
    "            'HABESTUDO_Q028A': ('B', 'A'),\n",
    "            'HABESTUDO_Q028B': ('B', 'A'),\n",
    "            'HABESTUDO_Q028C': ('B', 'A'),\n",
    "            'HABESTUDO_Q028D': ('B', 'A'),\n",
    "            'HABESTUDO_Q028E': ('B', 'A'),\n",
    "            'HABESTUDO_Q028F': ('B', 'A'),\n",
    "            'HABESTUDO_Q028G': ('B', 'A'),\n",
    "            'HABESTUDO_Q028H': ('B', 'A'),\n",
    "            'HABESTUDO_Q028I': ('B', 'A'),\n",
    "            'HABESTUDO_Q028J': ('B', 'A'),\n",
    "            'HABESTUDO_Q028K': ('B', 'A'),\n",
    "            'HABESTUDO_Q028L': ('B', 'A'),\n",
    "            'HABESTUDO_Q028M': ('B', 'A'),\n",
    "            'HABESTUDO_Q028N': ('B', 'A'),\n",
    "            'HABESTUDO_Q028O': ('B', 'A'),\n",
    "            'HABESTUDO_Q028P': ('B', 'A'),\n",
    "            'HABESTUDO_Q028Q': ('B', 'A'),\n",
    "            'HABESTUDO_Q028R': ('B', 'A'),\n",
    "            },\n",
    "    }\n",
    "\n",
    "    hab_estudo_columns = [column for columns_dict in hab_estudo_transformation_dict.values() for column in columns_dict.keys()]\n",
    "    hab_estudo_columns = ['NU_INSCRICAO'] + hab_estudo_columns\n",
    "\n",
    "    filtered_df = filtered_df.join(full_df[hab_estudo_columns].set_index('NU_INSCRICAO'), on='NU_INSCRICAO', how='inner')\n",
    "    filtered_df = filtered_df.drop(columns=hab_estudo_transformation_dict.keys())\n",
    "\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data = get_interest_hab_estudo(filtered_aggregated_df, aggregated_df)\n",
    "complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['PARTICIPANTE_TP_ST_CONCLUSAO', 'PARTICIPANTE_TP_ANO_CONCLUIU', 'PARTICIPANTE_IN_TREINEIRO', 'PARTICIPANTE_TP_PRESENCA_CN', 'PARTICIPANTE_TP_PRESENCA_CH', 'PARTICIPANTE_TP_PRESENCA_LC', 'PARTICIPANTE_TP_PRESENCA_MT', 'NOTAS_NU_ACERTOS_MEDIO', 'NOTAS_NU_ACERTOS_CN', 'NOTAS_NU_ACERTOS_CH', 'NOTAS_NU_ACERTOS_LC', 'NOTAS_NU_ACERTOS_MT', 'NOTAS_NU_NOTA_CN', 'NOTAS_NU_NOTA_CH', 'NOTAS_NU_NOTA_LC', 'NOTAS_NU_NOTA_MT', 'NOTAS_NU_NOTA_REDACAO', 'PARTICIPANTE_TP_STATUS_REDACAO', 'NOTAS_NU_NOTA_COMP1', 'NOTAS_NU_NOTA_COMP2', 'NOTAS_NU_NOTA_COMP3', 'NOTAS_NU_NOTA_COMP4', 'NOTAS_NU_NOTA_COMP5', 'NOTAS_NU_ACERTOS_TOTAL', 'PARTICIPANTE_TP_LINGUA']\n",
    "\n",
    "complete_data = complete_data.drop(columns=columns_to_drop)\n",
    "complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data.to_csv('../complete_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_creation_query = '''\n",
    "CREATE TABLE projeto_enem.complete_data (\n",
    "\t\"NU_INSCRICAO\" BIGINT PRIMARY KEY,\n",
    "\t\"PARTICIPANTE_TP_FAIXA_ETARIA\" INTEGER,\n",
    "\t\"PARTICIPANTE_TP_SEXO\" VARCHAR(1),\n",
    "\t\"PARTICIPANTE_TP_COR_RACA\" INTEGER,\n",
    "\t\"PARTICIPANTE_TP_ESCOLA\" INTEGER,\n",
    "\t\"PARTICIPANTE_REGIAO_ESCOLA\" VARCHAR(12),\n",
    "\t\"NOTAS_NU_NOTA_MEDIA\" FLOAT,\n",
    "    \"NOTAS_NU_NOTA_CONCEITO\" INTEGER,\n",
    "\t\"PARTICIPANTE_RENDA_PER_CAPITA\" FLOAT,\n",
    "\t\"HABESTUDO_Q005\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q006\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q007\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q008\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q021\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q022\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q009\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q010\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q011\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q012\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q013\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q014\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q015\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q016\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q017\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q018\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q019\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q020\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q023\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q024\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q027\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028A\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028B\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028C\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028D\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028E\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028F\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028G\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028H\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028I\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028J\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028K\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028L\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028M\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028N\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028O\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028P\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028Q\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028R\" VARCHAR(1)\n",
    ");\n",
    "'''\n",
    "\n",
    "complete_data_csv_query = '''\n",
    "COPY projeto_enem.complete_data(\"NU_INSCRICAO\", \"PARTICIPANTE_TP_FAIXA_ETARIA\", \"PARTICIPANTE_TP_SEXO\", \"PARTICIPANTE_TP_COR_RACA\", \"PARTICIPANTE_TP_ESCOLA\", \"PARTICIPANTE_REGIAO_ESCOLA\", \"NOTAS_NU_NOTA_MEDIA\", \"NOTAS_NU_NOTA_CONCEITO\", \"PARTICIPANTE_RENDA_PER_CAPITA\", \"HABESTUDO_Q005\", \"HABESTUDO_Q006\", \"HABESTUDO_Q007\", \"HABESTUDO_Q008\", \"HABESTUDO_Q021\", \"HABESTUDO_Q022\", \"HABESTUDO_Q009\", \"HABESTUDO_Q010\", \"HABESTUDO_Q011\", \"HABESTUDO_Q012\", \"HABESTUDO_Q013\", \"HABESTUDO_Q014\", \"HABESTUDO_Q015\", \"HABESTUDO_Q016\", \"HABESTUDO_Q017\", \"HABESTUDO_Q018\", \"HABESTUDO_Q019\", \"HABESTUDO_Q020\", \"HABESTUDO_Q023\", \"HABESTUDO_Q024\", \"HABESTUDO_Q027\", \"HABESTUDO_Q028A\", \"HABESTUDO_Q028B\", \"HABESTUDO_Q028C\", \"HABESTUDO_Q028D\", \"HABESTUDO_Q028E\", \"HABESTUDO_Q028F\", \"HABESTUDO_Q028G\", \"HABESTUDO_Q028H\", \"HABESTUDO_Q028I\", \"HABESTUDO_Q028J\", \"HABESTUDO_Q028K\", \"HABESTUDO_Q028L\", \"HABESTUDO_Q028M\", \"HABESTUDO_Q028N\", \"HABESTUDO_Q028O\", \"HABESTUDO_Q028P\", \"HABESTUDO_Q028Q\", \"HABESTUDO_Q028R\")\n",
    "FROM STDIN\n",
    "WITH (DELIMITER ',',\n",
    "ENCODING 'utf8',\n",
    "FORMAT CSV,\n",
    "HEADER);\n",
    "'''\n",
    "\n",
    "\n",
    "with db_connection() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(complete_data_creation_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    with open('../complete_df.csv', encoding='utf8') as complete_data_csv_file:\n",
    "        cursor.copy_expert(complete_data_csv_query, complete_data_csv_file)\n",
    "        conn.commit()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisando importância das novas variáveis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with db_connection() as conn, conn.cursor() as cursor:\n",
    "    query = '''\n",
    "    SELECT *\n",
    "    FROM projeto_enem.complete_data\n",
    "    ORDER BY \"NU_INSCRICAO\" ASC;\n",
    "    '''\n",
    "\n",
    "    cursor.execute(query)\n",
    "    complete_data_fetched = cursor.fetchall()\n",
    "    complete_data_columns = tuple(desc[0] for desc in cursor.description)\n",
    "\n",
    "\n",
    "complete_data = pd.DataFrame(complete_data_fetched, columns=complete_data_columns)\n",
    "complete_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ordinal:** 'HABESTUDO_Q005', 'HABESTUDO_Q006', 'HABESTUDO_Q007', 'HABESTUDO_Q008', 'HABESTUDO_Q021', 'HABESTUDO_Q022', 'HABESTUDO_Q009', 'HABESTUDO_Q010', 'HABESTUDO_Q011', 'HABESTUDO_Q012', 'HABESTUDO_Q013', 'HABESTUDO_Q014', 'HABESTUDO_Q015', 'HABESTUDO_Q016', 'HABESTUDO_Q017', 'HABESTUDO_Q018', 'HABESTUDO_Q019', 'HABESTUDO_Q020', 'HABESTUDO_Q023', 'HABESTUDO_Q024', 'HABESTUDO_Q027', 'HABESTUDO_Q028A', 'HABESTUDO_Q028B', 'HABESTUDO_Q028C', 'HABESTUDO_Q028D', 'HABESTUDO_Q028E', 'HABESTUDO_Q028F', 'HABESTUDO_Q028G', 'HABESTUDO_Q028H', 'HABESTUDO_Q028I', 'HABESTUDO_Q028J', 'HABESTUDO_Q028K', 'HABESTUDO_Q028L', 'HABESTUDO_Q028M', 'HABESTUDO_Q028N', 'HABESTUDO_Q028O', 'HABESTUDO_Q028P', 'HABESTUDO_Q028Q', 'HABESTUDO_Q028R'\n",
    "\n",
    "**nominal:** 'PARTICIPANTE_TP_SEXO', 'PARTICIPANTE_REGIAO_ESCOLA'\n",
    "\n",
    "**numerical:** 'NU_INSCRICAO', 'PARTICIPANTE_TP_FAIXA_ETARIA', 'PARTICIPANTE_TP_COR_RACA', 'PARTICIPANTE_TP_ST_CONCLUSAO', 'PARTICIPANTE_TP_ANO_CONCLUIU', 'PARTICIPANTE_TP_ESCOLA', 'PARTICIPANTE_IN_TREINEIRO', 'PARTICIPANTE_TP_PRESENCA_CN', 'PARTICIPANTE_TP_PRESENCA_CH', 'PARTICIPANTE_TP_PRESENCA_LC', 'PARTICIPANTE_TP_PRESENCA_MT', 'NOTAS_NU_NOTA_CN', 'NOTAS_NU_NOTA_CH', 'NOTAS_NU_NOTA_LC', 'NOTAS_NU_NOTA_MT', 'NOTAS_NU_NOTA_REDACAO', 'PARTICIPANTE_TP_STATUS_REDACAO', 'NOTAS_NU_NOTA_COMP1', 'NOTAS_NU_NOTA_COMP2', 'NOTAS_NU_NOTA_COMP3', 'NOTAS_NU_NOTA_COMP4', 'NOTAS_NU_NOTA_COMP5', 'NOTAS_NU_NOTA_MEDIA', 'NOTAS_NU_NOTA_CONCEITO', 'NOTAS_NU_ACERTOS_CN', 'NOTAS_NU_ACERTOS_CH', 'NOTAS_NU_ACERTOS_LC', 'NOTAS_NU_ACERTOS_MT', 'NOTAS_NU_ACERTOS_TOTAL', 'NOTAS_NU_ACERTOS_MEDIO', 'PARTICIPANTE_TP_LINGUA', 'PARTICIPANTE_RENDA_PER_CAPITA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['HABESTUDO_Q005', 'HABESTUDO_Q006', 'HABESTUDO_Q007', 'HABESTUDO_Q008', 'HABESTUDO_Q021', 'HABESTUDO_Q022', 'HABESTUDO_Q009', 'HABESTUDO_Q010', 'HABESTUDO_Q011', 'HABESTUDO_Q012', 'HABESTUDO_Q013', 'HABESTUDO_Q014', 'HABESTUDO_Q015', 'HABESTUDO_Q016', 'HABESTUDO_Q017', 'HABESTUDO_Q018', 'HABESTUDO_Q019', 'HABESTUDO_Q020', 'HABESTUDO_Q023', 'HABESTUDO_Q024', 'HABESTUDO_Q027', 'HABESTUDO_Q028A', 'HABESTUDO_Q028B', 'HABESTUDO_Q028C', 'HABESTUDO_Q028D', 'HABESTUDO_Q028E', 'HABESTUDO_Q028F', 'HABESTUDO_Q028G', 'HABESTUDO_Q028H', 'HABESTUDO_Q028I', 'HABESTUDO_Q028J', 'HABESTUDO_Q028K', 'HABESTUDO_Q028L', 'HABESTUDO_Q028M', 'HABESTUDO_Q028N', 'HABESTUDO_Q028O', 'HABESTUDO_Q028P', 'HABESTUDO_Q028Q', 'HABESTUDO_Q028R']\n",
    "nominal_features = list(set(complete_data.select_dtypes(include='object').columns.values) - set(ordinal_features))\n",
    "numerical_features = list(set(complete_data.select_dtypes(exclude='object').columns.values) - set(ordinal_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('encoder', OrdinalEncoder(categories=[\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q005\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q006\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q007\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q008\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q021\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q022\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q009\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q010\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q011\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q012\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q013\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q014\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q015\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q016\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q017\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q018\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q019\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q020\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q023\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q024\n",
    "        ('B', 'A'),   # HABESTUDO_Q027\n",
    "        ('B', 'A'),   # HABESTUDO_Q028A\n",
    "        ('B', 'A'),   # HABESTUDO_Q028B\n",
    "        ('B', 'A'),   # HABESTUDO_Q028C\n",
    "        ('B', 'A'),   # HABESTUDO_Q028D\n",
    "        ('B', 'A'),   # HABESTUDO_Q028E\n",
    "        ('B', 'A'),   # HABESTUDO_Q028F\n",
    "        ('B', 'A'),   # HABESTUDO_Q028G\n",
    "        ('B', 'A'),   # HABESTUDO_Q028H\n",
    "        ('B', 'A'),   # HABESTUDO_Q028I\n",
    "        ('B', 'A'),   # HABESTUDO_Q028J\n",
    "        ('B', 'A'),   # HABESTUDO_Q028K\n",
    "        ('B', 'A'),   # HABESTUDO_Q028L\n",
    "        ('B', 'A'),   # HABESTUDO_Q028M\n",
    "        ('B', 'A'),   # HABESTUDO_Q028N\n",
    "        ('B', 'A'),   # HABESTUDO_Q028O\n",
    "        ('B', 'A'),   # HABESTUDO_Q028P\n",
    "        ('B', 'A'),   # HABESTUDO_Q028Q\n",
    "        ('B', 'A'),   # HABESTUDO_Q028R\n",
    "    ])),\n",
    "])\n",
    "\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('ordinal', ordinal_transformer, ordinal_features),\n",
    "    ('nominal', nominal_transformer, nominal_features),\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = complete_data.drop(columns=['NU_INSCRICAO', 'NOTAS_NU_NOTA_MEDIA', 'NOTAS_NU_NOTA_CONCEITO'])\n",
    "\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "y_numerical_transformed = complete_data['NOTAS_NU_NOTA_MEDIA']\n",
    "y_categorical_transformed = complete_data['NOTAS_NU_NOTA_CONCEITO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_feature_names = preprocessor.get_feature_names_out()\n",
    "preprocessor_feature_names = [re.sub(r'.+__', '', item) for item in preprocessor_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = pd.DataFrame(X_transformed, columns=preprocessor_feature_names)\n",
    "X_transformed = X_transformed.drop(columns='PARTICIPANTE_TP_SEXO_M').reset_index(drop=True)\n",
    "X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical_train, X_numerical_test, y_numerical_train, y_numerical_test = train_test_split(X_transformed, y_numerical_transformed, test_size=0.3, random_state=SEED)\n",
    "\n",
    "X_categorical_train, X_categorical_test, y_categorical_train, y_categorical_test = train_test_split(X_transformed, y_categorical_transformed, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accelerating sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=SEED)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_pipe.fit(X_categorical_train, y_categorical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_accuracy_scores = cross_val_score(randomforest_classifier_pipe, X_transformed, y_categorical_transformed, cv=5, scoring='balanced_accuracy')\n",
    "randomforest_classifier_accuracy_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_precision_scores = cross_val_score(randomforest_classifier_pipe, X_transformed, y_categorical_transformed, cv=5, scoring='precision_weighted')\n",
    "randomforest_classifier_precision_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_recall_scores = cross_val_score(randomforest_classifier_pipe, X_transformed, y_categorical_transformed, cv=5, scoring='recall_weighted')\n",
    "randomforest_classifier_recall_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_f1_scores = cross_val_score(randomforest_classifier_pipe, X_transformed, y_categorical_transformed, cv=5, scoring='f1_weighted')\n",
    "randomforest_classifier_f1_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(randomforest_classifier_pipe, X_transformed, y_categorical_transformed, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_feature_importances = pd.Series(randomforest_classifier_pipe['classifier'].feature_importances_, index=X_categorical_train.columns)\n",
    "randomforest_classifier_feature_importances = randomforest_classifier_feature_importances.sort_values(ascending=False)\n",
    "randomforest_classifier_feature_importances = randomforest_classifier_feature_importances.apply(lambda x: round(100*x, 2))\n",
    "randomforest_classifier_feature_importances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', RandomForestRegressor(random_state=SEED)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_pipe.fit(X_numerical_train, y_numerical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_mae_scores = -1 * cross_val_score(randomforest_regressor_pipe, X_transformed, y_numerical_transformed, cv=5, scoring='neg_mean_absolute_error')\n",
    "randomforest_regressor_mae_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_rmse_scores = -1 * cross_val_score(randomforest_regressor_pipe, X_transformed, y_numerical_transformed, cv=5, scoring='neg_root_mean_squared_error')\n",
    "randomforest_regressor_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_r2_scores = cross_val_score(randomforest_regressor_pipe, X_transformed, y_numerical_transformed, cv=5, scoring='r2')\n",
    "randomforest_regressor_r2_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_mape_scores = -1 * cross_val_score(randomforest_regressor_pipe, X_transformed, y_numerical_transformed, cv=5, scoring='neg_mean_absolute_percentage_error')\n",
    "randomforest_regressor_mape_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_feature_importances = pd.Series(randomforest_regressor_pipe['regressor'].feature_importances_, index=X_numerical_train.columns)\n",
    "randomforest_regressor_feature_importances = randomforest_regressor_feature_importances.sort_values(ascending=False)\n",
    "randomforest_regressor_feature_importances = randomforest_regressor_feature_importances.apply(lambda x: round(100*x, 2))\n",
    "randomforest_regressor_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decelerating sklearn\n",
    "unpatch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_feature_importances = pd.concat([pd.DataFrame(randomforest_classifier_feature_importances, columns=['classifier_importance']).reset_index(names='classifier_column'), pd.DataFrame(randomforest_regressor_feature_importances, columns=['regressor_importance']).reset_index(names='regressor_column')], axis=1).sort_values(['classifier_importance', 'regressor_importance'], ascending=False)\n",
    "randomforest_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hab_estudo_correspondent_column_names(df: pd.DataFrame, changing_columns: list) -> pd.DataFrame:\n",
    "    '''\n",
    "    Substitui as colunas de categoria dos hábitos de estudo pelo seu significado.\n",
    "\n",
    "    :params:\n",
    "    - df: DataFrame previamente tratado com todos os dados para substituição.\n",
    "    - changing_columns: colunas com dados para serem alterados.\n",
    "\n",
    "    Returns a DataFrame.\n",
    "    '''\n",
    "\n",
    "    hab_estudo_column_correspondent_names = {\n",
    "        'HABESTUDO_Q005': 'Organizei cronograma de estudos com tempos mais longos e mais curtos para estudar de acordo com a dificuldade das matérias',\n",
    "        'HABESTUDO_Q006': 'Reservei tempos mais longos e mais curtos para estudar de acordo com a dificuldade das matérias',\n",
    "        'HABESTUDO_Q007': 'Organizei material para ser estudado',\n",
    "        'HABESTUDO_Q008': 'Eu me dediquei aos horários programados de estudo de acordo com a dificuldade das matérias',\n",
    "        'HABESTUDO_Q021': 'Entrei nas aulas online por videoconferência sem atraso da minha parte',\n",
    "        'HABESTUDO_Q022': 'Assisti todas as aulas online nas datas programadas para estudo',\n",
    "        'HABESTUDO_Q009': 'Li os textos indicados em cada matéria antes de assistir as aulas ou videoaulas sobre o assunto dos textos',\n",
    "        'HABESTUDO_Q010': 'Resumi os textos das matérias, destacando as partes mais importantes',\n",
    "        'HABESTUDO_Q011': 'Resumi as videoaulas ou os podcasts, destacando as partes mais importantes',\n",
    "        'HABESTUDO_Q012': 'Fiz as atividades das matérias para fixação de conteúdo',\n",
    "        'HABESTUDO_Q013': 'Fiz atividades avaliativas, inclusive simulados, para verificar o quanto aprendi durante a pandemia',\n",
    "        'HABESTUDO_Q014': 'Aproveitei o tempo das aulas online ou atividades de reforço, sem desperdiçá-lo com distrações',\n",
    "        'HABESTUDO_Q015': 'Anotei as explicações obtidas em videoaulas ou podcasts das matérias',\n",
    "        'HABESTUDO_Q016': 'Anotei as informações que obtive ao assistir vídeos complementares de assuntos do meu interesse',\n",
    "        'HABESTUDO_Q017': 'Destaquei as dúvidas que tive ao ler os textos das disciplinas para esclarecer com os professores',\n",
    "        'HABESTUDO_Q018': 'Estruturei as principais ideias para produzir redações',\n",
    "        'HABESTUDO_Q019': 'Treinei redação',\n",
    "        'HABESTUDO_Q020': 'Participei de fóruns de discussão por matéria para tirar dúvidas',\n",
    "        'HABESTUDO_Q023': 'Revisei as anotações das aulas, os resumos e anotações dos demais materiais que li ou assisti',\n",
    "        'HABESTUDO_Q024': 'Reassisti as videoaulas e os podcasts das matérias',\n",
    "        'HABESTUDO_Q027': 'Você vivenciou problemas em sua rotina para estudar ou manter-se informado(a) durante a pandemia?',\n",
    "        'HABESTUDO_Q028A': 'Eu me senti desestimulado(a) por não ter colegas com quem interagir sobre o que eu estava estudando',\n",
    "        'HABESTUDO_Q028B': 'Tive dificuldade de compreender os conteúdos por falta de explicações de um professor em tempo real',\n",
    "        'HABESTUDO_Q028C': 'Fiquei por muito tempo diante das telas, sem pequenos intervalos para descansar',\n",
    "        'HABESTUDO_Q028D': 'Reduzi a prática de atividades físicas',\n",
    "        'HABESTUDO_Q028E': 'Dormi por menos tempo',\n",
    "        'HABESTUDO_Q028F': 'Tive episódios de insônia',\n",
    "        'HABESTUDO_Q028G': 'Senti dificuldade em manter a motivação para estudar por minha conta',\n",
    "        'HABESTUDO_Q028H': 'Senti dificuldade em me motivar a cumprir meu cronograma',\n",
    "        'HABESTUDO_Q028I': 'Senti medo de não conseguir aprender os conteúdos',\n",
    "        'HABESTUDO_Q028J': 'Senti ansiedade devido ao isolamento social e ao receio de contágio da doença',\n",
    "        'HABESTUDO_Q028K': 'Dediquei tempo para ajudar algum familiar a estudar em casa',\n",
    "        'HABESTUDO_Q028L': 'Precisei ficar em repouso porque tive Covid com sintomas',\n",
    "        'HABESTUDO_Q028M': 'Precisei ficar em repouso porque tive outra doença',\n",
    "        'HABESTUDO_Q028N': 'Precisei cuidar de algum familiar que teve Covid com sintomas',\n",
    "        'HABESTUDO_Q028O': 'Precisei cuidar de algum familiar que teve outra doença',\n",
    "        'HABESTUDO_Q028P': 'Tive que cuidar do(s) meu(s) irmão(s) menor(es) para meus pais trabalharem',\n",
    "        'HABESTUDO_Q028Q': 'Tive que começar a trabalhar em casa para obter renda',\n",
    "        'HABESTUDO_Q028R': 'Tive que trabalhar em serviço considerado essencial durante a pandemia',\n",
    "    }\n",
    "\n",
    "    for column in changing_columns:\n",
    "        df.loc[:, column] = df[column].replace(hab_estudo_column_correspondent_names)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_feature_importances = get_hab_estudo_correspondent_column_names(randomforest_feature_importances, ['classifier_column', 'regressor_column'])\n",
    "randomforest_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_feature_importances[['regressor_column', 'regressor_importance']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analisando importância em escola particular**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with db_connection() as conn, conn.cursor() as cursor:\n",
    "    query = '''\n",
    "    SELECT *\n",
    "    FROM projeto_enem.complete_data\n",
    "    ORDER BY \"NU_INSCRICAO\" ASC;\n",
    "    '''\n",
    "\n",
    "    cursor.execute(query)\n",
    "    complete_data_fetched = cursor.fetchall()\n",
    "    complete_data_columns = tuple(desc[0] for desc in cursor.description)\n",
    "\n",
    "\n",
    "complete_data = pd.DataFrame(complete_data_fetched, columns=complete_data_columns)\n",
    "complete_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_private = complete_data[complete_data['PARTICIPANTE_TP_ESCOLA'] == 3]\n",
    "complete_data_private = complete_data_private.drop(columns='PARTICIPANTE_TP_ESCOLA')\n",
    "complete_data_private"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ordinal:** 'HABESTUDO_Q005', 'HABESTUDO_Q006', 'HABESTUDO_Q007', 'HABESTUDO_Q008', 'HABESTUDO_Q021', 'HABESTUDO_Q022', 'HABESTUDO_Q009', 'HABESTUDO_Q010', 'HABESTUDO_Q011', 'HABESTUDO_Q012', 'HABESTUDO_Q013', 'HABESTUDO_Q014', 'HABESTUDO_Q015', 'HABESTUDO_Q016', 'HABESTUDO_Q017', 'HABESTUDO_Q018', 'HABESTUDO_Q019', 'HABESTUDO_Q020', 'HABESTUDO_Q023', 'HABESTUDO_Q024', 'HABESTUDO_Q027', 'HABESTUDO_Q028A', 'HABESTUDO_Q028B', 'HABESTUDO_Q028C', 'HABESTUDO_Q028D', 'HABESTUDO_Q028E', 'HABESTUDO_Q028F', 'HABESTUDO_Q028G', 'HABESTUDO_Q028H', 'HABESTUDO_Q028I', 'HABESTUDO_Q028J', 'HABESTUDO_Q028K', 'HABESTUDO_Q028L', 'HABESTUDO_Q028M', 'HABESTUDO_Q028N', 'HABESTUDO_Q028O', 'HABESTUDO_Q028P', 'HABESTUDO_Q028Q', 'HABESTUDO_Q028R'\n",
    "\n",
    "**nominal:** 'PARTICIPANTE_TP_SEXO', 'PARTICIPANTE_REGIAO_ESCOLA'\n",
    "\n",
    "**numerical:** 'NU_INSCRICAO', 'PARTICIPANTE_TP_FAIXA_ETARIA', 'PARTICIPANTE_TP_COR_RACA', 'PARTICIPANTE_TP_ST_CONCLUSAO', 'PARTICIPANTE_TP_ANO_CONCLUIU', 'PARTICIPANTE_TP_ESCOLA', 'PARTICIPANTE_IN_TREINEIRO', 'PARTICIPANTE_TP_PRESENCA_CN', 'PARTICIPANTE_TP_PRESENCA_CH', 'PARTICIPANTE_TP_PRESENCA_LC', 'PARTICIPANTE_TP_PRESENCA_MT', 'NOTAS_NU_NOTA_CN', 'NOTAS_NU_NOTA_CH', 'NOTAS_NU_NOTA_LC', 'NOTAS_NU_NOTA_MT', 'NOTAS_NU_NOTA_REDACAO', 'PARTICIPANTE_TP_STATUS_REDACAO', 'NOTAS_NU_NOTA_COMP1', 'NOTAS_NU_NOTA_COMP2', 'NOTAS_NU_NOTA_COMP3', 'NOTAS_NU_NOTA_COMP4', 'NOTAS_NU_NOTA_COMP5', 'NOTAS_NU_NOTA_MEDIA', 'NOTAS_NU_NOTA_CONCEITO', 'NOTAS_NU_ACERTOS_CN', 'NOTAS_NU_ACERTOS_CH', 'NOTAS_NU_ACERTOS_LC', 'NOTAS_NU_ACERTOS_MT', 'NOTAS_NU_ACERTOS_TOTAL', 'NOTAS_NU_ACERTOS_MEDIO', 'PARTICIPANTE_TP_LINGUA', 'PARTICIPANTE_RENDA_PER_CAPITA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_features = ['HABESTUDO_Q005', 'HABESTUDO_Q006', 'HABESTUDO_Q007', 'HABESTUDO_Q008', 'HABESTUDO_Q021', 'HABESTUDO_Q022', 'HABESTUDO_Q009', 'HABESTUDO_Q010', 'HABESTUDO_Q011', 'HABESTUDO_Q012', 'HABESTUDO_Q013', 'HABESTUDO_Q014', 'HABESTUDO_Q015', 'HABESTUDO_Q016', 'HABESTUDO_Q017', 'HABESTUDO_Q018', 'HABESTUDO_Q019', 'HABESTUDO_Q020', 'HABESTUDO_Q023', 'HABESTUDO_Q024', 'HABESTUDO_Q027', 'HABESTUDO_Q028A', 'HABESTUDO_Q028B', 'HABESTUDO_Q028C', 'HABESTUDO_Q028D', 'HABESTUDO_Q028E', 'HABESTUDO_Q028F', 'HABESTUDO_Q028G', 'HABESTUDO_Q028H', 'HABESTUDO_Q028I', 'HABESTUDO_Q028J', 'HABESTUDO_Q028K', 'HABESTUDO_Q028L', 'HABESTUDO_Q028M', 'HABESTUDO_Q028N', 'HABESTUDO_Q028O', 'HABESTUDO_Q028P', 'HABESTUDO_Q028Q', 'HABESTUDO_Q028R']\n",
    "nominal_features = list(set(complete_data.select_dtypes(include='object').columns.values) - set(ordinal_features))\n",
    "numerical_features = list(set(complete_data.select_dtypes(exclude='object').columns.values) - set(ordinal_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('encoder', OrdinalEncoder(categories=[\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q005\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q006\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q007\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q008\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q021\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q022\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q009\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q010\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q011\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q012\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q013\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q014\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q015\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q016\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q017\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q018\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q019\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q020\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q023\n",
    "        ('A', 'B', 'C', 'D'),   # HABESTUDO_Q024\n",
    "        ('B', 'A'),   # HABESTUDO_Q027\n",
    "        ('B', 'A'),   # HABESTUDO_Q028A\n",
    "        ('B', 'A'),   # HABESTUDO_Q028B\n",
    "        ('B', 'A'),   # HABESTUDO_Q028C\n",
    "        ('B', 'A'),   # HABESTUDO_Q028D\n",
    "        ('B', 'A'),   # HABESTUDO_Q028E\n",
    "        ('B', 'A'),   # HABESTUDO_Q028F\n",
    "        ('B', 'A'),   # HABESTUDO_Q028G\n",
    "        ('B', 'A'),   # HABESTUDO_Q028H\n",
    "        ('B', 'A'),   # HABESTUDO_Q028I\n",
    "        ('B', 'A'),   # HABESTUDO_Q028J\n",
    "        ('B', 'A'),   # HABESTUDO_Q028K\n",
    "        ('B', 'A'),   # HABESTUDO_Q028L\n",
    "        ('B', 'A'),   # HABESTUDO_Q028M\n",
    "        ('B', 'A'),   # HABESTUDO_Q028N\n",
    "        ('B', 'A'),   # HABESTUDO_Q028O\n",
    "        ('B', 'A'),   # HABESTUDO_Q028P\n",
    "        ('B', 'A'),   # HABESTUDO_Q028Q\n",
    "        ('B', 'A'),   # HABESTUDO_Q028R\n",
    "    ])),\n",
    "])\n",
    "\n",
    "nominal_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder()),\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('ordinal', ordinal_transformer, ordinal_features),\n",
    "    ('nominal', nominal_transformer, nominal_features),\n",
    "], remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = complete_data_private.drop(columns=['NU_INSCRICAO', 'NOTAS_NU_NOTA_MEDIA', 'NOTAS_NU_NOTA_CONCEITO'])\n",
    "\n",
    "X_transformed = preprocessor.fit_transform(X)\n",
    "y_numerical_transformed = complete_data_private['NOTAS_NU_NOTA_MEDIA']\n",
    "y_categorical_transformed = complete_data_private['NOTAS_NU_NOTA_CONCEITO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor_feature_names = preprocessor.get_feature_names_out()\n",
    "preprocessor_feature_names = [re.sub(r'.+__', '', item) for item in preprocessor_feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transformed = pd.DataFrame(X_transformed, columns=preprocessor_feature_names)\n",
    "X_transformed = X_transformed.drop(columns='PARTICIPANTE_TP_SEXO_M').reset_index(drop=True)\n",
    "X_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numerical_train, X_numerical_test, y_numerical_train, y_numerical_test = train_test_split(X_transformed, y_numerical_transformed, test_size=0.3, random_state=SEED)\n",
    "\n",
    "X_categorical_train, X_categorical_test, y_categorical_train, y_categorical_test = train_test_split(X_transformed, y_categorical_transformed, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accelerating sklearn\n",
    "patch_sklearn()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', RandomForestClassifier(random_state=SEED)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_pipe.fit(X_categorical_train, y_categorical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_accuracy_scores = cross_val_score(randomforest_classifier_pipe, X_transformed, y_categorical_transformed, cv=5, scoring='balanced_accuracy')\n",
    "randomforest_classifier_accuracy_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_precision_scores = cross_val_score(randomforest_classifier_pipe, X_transformed, y_categorical_transformed, cv=5, scoring='precision_weighted')\n",
    "randomforest_classifier_precision_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_recall_scores = cross_val_score(randomforest_classifier_pipe, X_transformed, y_categorical_transformed, cv=5, scoring='recall_weighted')\n",
    "randomforest_classifier_recall_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_f1_scores = cross_val_score(randomforest_classifier_pipe, X_transformed, y_categorical_transformed, cv=5, scoring='f1_weighted')\n",
    "randomforest_classifier_f1_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_estimator(randomforest_classifier_pipe, X_transformed, y_categorical_transformed, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_classifier_feature_importances = pd.Series(randomforest_classifier_pipe['classifier'].feature_importances_, index=X_categorical_train.columns)\n",
    "randomforest_classifier_feature_importances = randomforest_classifier_feature_importances.sort_values(ascending=False)\n",
    "randomforest_classifier_feature_importances = randomforest_classifier_feature_importances.apply(lambda x: round(100*x, 2))\n",
    "randomforest_classifier_feature_importances"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_pipe = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', RandomForestRegressor(random_state=SEED)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_pipe.fit(X_numerical_train, y_numerical_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_mae_scores = -1 * cross_val_score(randomforest_regressor_pipe, X_transformed, y_numerical_transformed, cv=5, scoring='neg_mean_absolute_error')\n",
    "randomforest_regressor_mae_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_rmse_scores = -1 * cross_val_score(randomforest_regressor_pipe, X_transformed, y_numerical_transformed, cv=5, scoring='neg_root_mean_squared_error')\n",
    "randomforest_regressor_rmse_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_r2_scores = cross_val_score(randomforest_regressor_pipe, X_transformed, y_numerical_transformed, cv=5, scoring='r2')\n",
    "randomforest_regressor_r2_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_mape_scores = -1 * cross_val_score(randomforest_regressor_pipe, X_transformed, y_numerical_transformed, cv=5, scoring='neg_mean_absolute_percentage_error')\n",
    "randomforest_regressor_mape_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_regressor_feature_importances = pd.Series(randomforest_regressor_pipe['regressor'].feature_importances_, index=X_numerical_train.columns)\n",
    "randomforest_regressor_feature_importances = randomforest_regressor_feature_importances.sort_values(ascending=False)\n",
    "randomforest_regressor_feature_importances = randomforest_regressor_feature_importances.apply(lambda x: round(100*x, 2))\n",
    "randomforest_regressor_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decelerating sklearn\n",
    "unpatch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_feature_importances = pd.concat([pd.DataFrame(randomforest_classifier_feature_importances, columns=['classifier_importance']).reset_index(names='classifier_column'), pd.DataFrame(randomforest_regressor_feature_importances, columns=['regressor_importance']).reset_index(names='regressor_column')], axis=1).sort_values(['classifier_importance', 'regressor_importance'], ascending=False)\n",
    "randomforest_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hab_estudo_correspondent_column_names(df: pd.DataFrame, changing_columns: list) -> pd.DataFrame:\n",
    "    '''\n",
    "    Substitui as colunas de categoria dos hábitos de estudo pelo seu significado.\n",
    "\n",
    "    :params:\n",
    "    - df: DataFrame previamente tratado com todos os dados para substituição.\n",
    "    - changing_columns: colunas com dados para serem alterados.\n",
    "\n",
    "    Returns a DataFrame.\n",
    "    '''\n",
    "\n",
    "    hab_estudo_column_correspondent_names = {\n",
    "        'HABESTUDO_Q005': 'Organizei cronograma de estudos com tempos mais longos e mais curtos para estudar de acordo com a dificuldade das matérias',\n",
    "        'HABESTUDO_Q006': 'Reservei tempos mais longos e mais curtos para estudar de acordo com a dificuldade das matérias',\n",
    "        'HABESTUDO_Q007': 'Organizei material para ser estudado',\n",
    "        'HABESTUDO_Q008': 'Eu me dediquei aos horários programados de estudo de acordo com a dificuldade das matérias',\n",
    "        'HABESTUDO_Q021': 'Entrei nas aulas online por videoconferência sem atraso da minha parte',\n",
    "        'HABESTUDO_Q022': 'Assisti todas as aulas online nas datas programadas para estudo',\n",
    "        'HABESTUDO_Q009': 'Li os textos indicados em cada matéria antes de assistir as aulas ou videoaulas sobre o assunto dos textos',\n",
    "        'HABESTUDO_Q010': 'Resumi os textos das matérias, destacando as partes mais importantes',\n",
    "        'HABESTUDO_Q011': 'Resumi as videoaulas ou os podcasts, destacando as partes mais importantes',\n",
    "        'HABESTUDO_Q012': 'Fiz as atividades das matérias para fixação de conteúdo',\n",
    "        'HABESTUDO_Q013': 'Fiz atividades avaliativas, inclusive simulados, para verificar o quanto aprendi durante a pandemia',\n",
    "        'HABESTUDO_Q014': 'Aproveitei o tempo das aulas online ou atividades de reforço, sem desperdiçá-lo com distrações',\n",
    "        'HABESTUDO_Q015': 'Anotei as explicações obtidas em videoaulas ou podcasts das matérias',\n",
    "        'HABESTUDO_Q016': 'Anotei as informações que obtive ao assistir vídeos complementares de assuntos do meu interesse',\n",
    "        'HABESTUDO_Q017': 'Destaquei as dúvidas que tive ao ler os textos das disciplinas para esclarecer com os professores',\n",
    "        'HABESTUDO_Q018': 'Estruturei as principais ideias para produzir redações',\n",
    "        'HABESTUDO_Q019': 'Treinei redação',\n",
    "        'HABESTUDO_Q020': 'Participei de fóruns de discussão por matéria para tirar dúvidas',\n",
    "        'HABESTUDO_Q023': 'Revisei as anotações das aulas, os resumos e anotações dos demais materiais que li ou assisti',\n",
    "        'HABESTUDO_Q024': 'Reassisti as videoaulas e os podcasts das matérias',\n",
    "        'HABESTUDO_Q027': 'Você vivenciou problemas em sua rotina para estudar ou manter-se informado(a) durante a pandemia?',\n",
    "        'HABESTUDO_Q028A': 'Eu me senti desestimulado(a) por não ter colegas com quem interagir sobre o que eu estava estudando',\n",
    "        'HABESTUDO_Q028B': 'Tive dificuldade de compreender os conteúdos por falta de explicações de um professor em tempo real',\n",
    "        'HABESTUDO_Q028C': 'Fiquei por muito tempo diante das telas, sem pequenos intervalos para descansar',\n",
    "        'HABESTUDO_Q028D': 'Reduzi a prática de atividades físicas',\n",
    "        'HABESTUDO_Q028E': 'Dormi por menos tempo',\n",
    "        'HABESTUDO_Q028F': 'Tive episódios de insônia',\n",
    "        'HABESTUDO_Q028G': 'Senti dificuldade em manter a motivação para estudar por minha conta',\n",
    "        'HABESTUDO_Q028H': 'Senti dificuldade em me motivar a cumprir meu cronograma',\n",
    "        'HABESTUDO_Q028I': 'Senti medo de não conseguir aprender os conteúdos',\n",
    "        'HABESTUDO_Q028J': 'Senti ansiedade devido ao isolamento social e ao receio de contágio da doença',\n",
    "        'HABESTUDO_Q028K': 'Dediquei tempo para ajudar algum familiar a estudar em casa',\n",
    "        'HABESTUDO_Q028L': 'Precisei ficar em repouso porque tive Covid com sintomas',\n",
    "        'HABESTUDO_Q028M': 'Precisei ficar em repouso porque tive outra doença',\n",
    "        'HABESTUDO_Q028N': 'Precisei cuidar de algum familiar que teve Covid com sintomas',\n",
    "        'HABESTUDO_Q028O': 'Precisei cuidar de algum familiar que teve outra doença',\n",
    "        'HABESTUDO_Q028P': 'Tive que cuidar do(s) meu(s) irmão(s) menor(es) para meus pais trabalharem',\n",
    "        'HABESTUDO_Q028Q': 'Tive que começar a trabalhar em casa para obter renda',\n",
    "        'HABESTUDO_Q028R': 'Tive que trabalhar em serviço considerado essencial durante a pandemia',\n",
    "    }\n",
    "\n",
    "    for column in changing_columns:\n",
    "        df.loc[:, column] = df[column].replace(hab_estudo_column_correspondent_names)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_feature_importances = get_hab_estudo_correspondent_column_names(randomforest_feature_importances, ['classifier_column', 'regressor_column'])\n",
    "randomforest_feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "randomforest_feature_importances[['regressor_column', 'regressor_importance']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_data_private.to_csv('../complete_private_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_private_data_creation_query = '''\n",
    "CREATE TABLE projeto_enem.complete_private_data (\n",
    "\t\"NU_INSCRICAO\" BIGINT PRIMARY KEY,\n",
    "\t\"PARTICIPANTE_TP_FAIXA_ETARIA\" INTEGER,\n",
    "\t\"PARTICIPANTE_TP_SEXO\" VARCHAR(1),\n",
    "\t\"PARTICIPANTE_TP_COR_RACA\" INTEGER,\n",
    "\t\"PARTICIPANTE_REGIAO_ESCOLA\" VARCHAR(12),\n",
    "\t\"NOTAS_NU_NOTA_MEDIA\" FLOAT,\n",
    "    \"NOTAS_NU_NOTA_CONCEITO\" INTEGER,\n",
    "\t\"PARTICIPANTE_RENDA_PER_CAPITA\" FLOAT,\n",
    "\t\"HABESTUDO_Q005\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q006\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q007\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q008\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q021\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q022\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q009\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q010\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q011\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q012\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q013\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q014\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q015\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q016\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q017\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q018\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q019\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q020\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q023\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q024\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q027\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028A\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028B\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028C\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028D\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028E\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028F\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028G\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028H\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028I\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028J\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028K\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028L\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028M\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028N\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028O\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028P\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028Q\" VARCHAR(1),\n",
    "\t\"HABESTUDO_Q028R\" VARCHAR(1)\n",
    ");\n",
    "'''\n",
    "\n",
    "complete_private_data_csv_query = '''\n",
    "COPY projeto_enem.complete_private_data(\"NU_INSCRICAO\", \"PARTICIPANTE_TP_FAIXA_ETARIA\", \"PARTICIPANTE_TP_SEXO\", \"PARTICIPANTE_TP_COR_RACA\", \"PARTICIPANTE_REGIAO_ESCOLA\", \"NOTAS_NU_NOTA_MEDIA\", \"NOTAS_NU_NOTA_CONCEITO\", \"PARTICIPANTE_RENDA_PER_CAPITA\", \"HABESTUDO_Q005\", \"HABESTUDO_Q006\", \"HABESTUDO_Q007\", \"HABESTUDO_Q008\", \"HABESTUDO_Q021\", \"HABESTUDO_Q022\", \"HABESTUDO_Q009\", \"HABESTUDO_Q010\", \"HABESTUDO_Q011\", \"HABESTUDO_Q012\", \"HABESTUDO_Q013\", \"HABESTUDO_Q014\", \"HABESTUDO_Q015\", \"HABESTUDO_Q016\", \"HABESTUDO_Q017\", \"HABESTUDO_Q018\", \"HABESTUDO_Q019\", \"HABESTUDO_Q020\", \"HABESTUDO_Q023\", \"HABESTUDO_Q024\", \"HABESTUDO_Q027\", \"HABESTUDO_Q028A\", \"HABESTUDO_Q028B\", \"HABESTUDO_Q028C\", \"HABESTUDO_Q028D\", \"HABESTUDO_Q028E\", \"HABESTUDO_Q028F\", \"HABESTUDO_Q028G\", \"HABESTUDO_Q028H\", \"HABESTUDO_Q028I\", \"HABESTUDO_Q028J\", \"HABESTUDO_Q028K\", \"HABESTUDO_Q028L\", \"HABESTUDO_Q028M\", \"HABESTUDO_Q028N\", \"HABESTUDO_Q028O\", \"HABESTUDO_Q028P\", \"HABESTUDO_Q028Q\", \"HABESTUDO_Q028R\")\n",
    "FROM STDIN\n",
    "WITH (DELIMITER ',',\n",
    "ENCODING 'utf8',\n",
    "FORMAT CSV,\n",
    "HEADER);\n",
    "'''\n",
    "\n",
    "\n",
    "with db_connection() as conn, conn.cursor() as cursor:\n",
    "    cursor.execute(complete_private_data_creation_query)\n",
    "    conn.commit()\n",
    "    \n",
    "    with open('../complete_private_df.csv', encoding='utf8') as complete_private_data_csv_file:\n",
    "        cursor.copy_expert(complete_private_data_csv_query, complete_private_data_csv_file)\n",
    "        conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with db_connection() as conn, conn.cursor() as cursor:\n",
    "    query = '''\n",
    "    SELECT *\n",
    "    FROM projeto_enem.complete_private_data\n",
    "    ORDER BY \"NU_INSCRICAO\" ASC;\n",
    "    '''\n",
    "\n",
    "    cursor.execute(query)\n",
    "    complete_private_data_fetched = cursor.fetchall()\n",
    "    complete_private_data_columns = tuple(desc[0] for desc in cursor.description)\n",
    "\n",
    "\n",
    "complete_private_data = pd.DataFrame(complete_private_data_fetched, columns=complete_private_data_columns)\n",
    "complete_private_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
